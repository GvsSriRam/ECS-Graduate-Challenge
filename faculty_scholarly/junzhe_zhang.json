{
  "name": "Junzhe Zhang",
  "affiliation": "Syracuse University",
  "interests": [
    "causal inference",
    "artificial intelligence"
  ],
  "citedby": 1132,
  "h_index": 12,
  "i10_index": 12,
  "top_primary_author_publications": [
    {
      "title": "Fairness in decision-making—the causal explanation formula",
      "year": 2018,
      "abstract": "AI plays an increasingly prominent role in society since decisions that were once made by humans are now delegated to automated systems. These systems are currently in charge of deciding bank loans, criminals' incarceration, and the hiring of new employees, and it's not difficult to envision that they will in the future underpin most of the decisions in society. Despite the high complexity entailed by this task, there is still not much understanding of basic properties of such systems. For instance, we currently cannot detect (neither explain nor correct) whether an AI system can be deemed fair (ie, is abiding by the decision-constraints agreed by society) or it is reinforcing biases and perpetuating a preceding prejudicial practice. Issues of discrimination have been discussed extensively in political and legal circles, but there exists still not much understanding of the formal conditions that a system must meet to be deemed fair. In this paper, we use the language of structural causality (Pearl, 2000) to fill in this gap. We start by introducing three new fine-grained measures of transmission of change from stimulus to effect, which we called counterfactual direct (Ctf-DE), indirect (Ctf-IE), and spurious (Ctf-SE) effects. We then derive what we call the causal explanation formula, which allows the AI designer to quantitatively evaluate fairness and explain the total observed disparity of decisions through different discriminatory mechanisms. We apply these measures to various discrimination analysis tasks and run extensive simulations, including detection, evaluation, and optimization of decision-making under fairness constraints. We conclude studying the trade-off …",
      "venue": "Proceedings of the... AAAI Conference on Artificial Intelligence",
      "citations": 354,
      "authors": [
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "url": ""
    },
    {
      "title": "Equality of opportunity in classification: A causal approach",
      "year": 2018,
      "abstract": "The Equalized Odds (for short, EO) is one of the most popular measures of discrimination used in the supervised learning setting. It ascertains fairness through the balance of the misclassification rates (false positive and negative) across the protected groups--eg, in the context of law enforcement, an African-American defendant who would not commit a future crime will have an equal opportunity of being released, compared to a non-recidivating Caucasian defendant. Despite this noble goal, it has been acknowledged in the literature that statistical tests based on the EO are oblivious to the underlying causal mechanisms that generated the disparity in the first place (Hardt et al. 2016). This leads to a critical disconnect between statistical measures readable from the data and the meaning of discrimination in the legal system, where compelling evidence that the observed disparity is tied to a specific causal process deemed unfair by society is required to characterize discrimination. The goal of this paper is to develop a principled approach to connect the statistical disparities characterized by the EO and the underlying, elusive, and frequently unobserved, causal mechanisms that generated such inequality. We start by introducing a new family of counterfactual measures that allows one to explain the misclassification disparities in terms of the underlying mechanisms in an arbitrary, non-parametric structural causal model. This will, in turn, allow legal and data analysts to interpret currently deployed classifiers through causal lens, linking the statistical disparities found in the data to the corresponding causal processes. Leveraging the new family of …",
      "venue": "Advances in neural information processing systems",
      "citations": 109,
      "authors": [
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "url": ""
    },
    {
      "title": "Transfer learning in multi-armed bandit: a causal approach",
      "year": 2017,
      "abstract": "We leverage causal inference tools to support a principled and more robust transfer of knowledge in reinforcement learning (RL) settings. In particular, we tackle the problem of transferring knowledge across bandit agents in settings where causal effects cannot be identified by Pearl’s do-calculus nor standard off-policy learning techniques. Our new identification strategy combines two steps–first, deriving bounds over the arm’s distribution based on structural knowledge; second, incorporating these bounds in a novel bandit algorithm, B-kl-UCB. Simulations demonstrate that our strategy is consistently more efficient than the current (noncausal) state-of-the-art methods.",
      "venue": "Proceedings of the 26th International Joint Conference on Artificial Intelligence",
      "citations": 107,
      "authors": [
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "url": ""
    }
  ],
  "top_secondary_author_publications": [],
  "source": "scholar"
}